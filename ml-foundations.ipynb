{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EDA\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Exploring the Data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import polars as pl\n",
    "import polars.selectors as cs\n",
    "import sklearn \n",
    "import catboost\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# King County House Sales dataset from OpenML (includes Seattle)\n",
    "# this is an ARFF file, which is a text file with a specific format\n",
    "url = 'https://www.openml.org/data/download/22044765/dataset'\n",
    "cols = ['id', 'price', 'bedrooms', 'bathrooms', 'sqft_living', 'sqft_lot', 'floors', 'waterfront', 'view', \n",
    "        'condition', 'grade', 'sqft_above', 'sqft_basement', 'yr_built', 'yr_renovated',\n",
    "        'zipcode', 'lat', 'long', 'sqft_living15', 'sqft_lot15', 'date_year', 'date_month', 'date_day']\n",
    "\n",
    "raw = pl.read_csv(url, new_columns=cols, skip_rows=31, has_header=False)\n",
    "raw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(raw\n",
    " .to_pandas(use_pyarrow_extension_array=True)\n",
    " .corr()\n",
    " .style.background_gradient(cmap='RdBu', vmin=-1, vmax=1)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(raw\n",
    " .plot.scatter('sqft_living', 'price', alpha=0.1)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(raw\n",
    " .group_by('date_month', 'zipcode')\n",
    " .agg(pl.col('price').mean())\n",
    " .plot.line('date_month', 'price', by='zipcode')\n",
    " )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(raw\n",
    " .group_by('date_month', 'zipcode')\n",
    " .agg(pl.col('price').mean())\n",
    " .sort('date_month')\n",
    " .plot.line('date_month', 'price', by='zipcode', alpha=0.5)\n",
    " )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lat/long scatter plot\n",
    "(raw\n",
    " .sort('price')\n",
    " .plot.scatter(x='long', y='lat', alpha=0.5, c='price', s=1)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lat/long scatter plot\n",
    "(raw\n",
    " .filter(pl.col('price') > 1_000_000)\n",
    " .sort('price')\n",
    " .plot.scatter(x='long', y='lat', alpha=0.5, c='price', s=1)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Data Preprocessing\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tweak_housing(df):\n",
    "    return (df\n",
    "            .with_columns(zipcode=pl.col('zipcode').cast(pl.String).cast(pl.Categorical),\n",
    "                          date=pl.date(pl.col('date_year'), pl.col('date_month'), pl.col('date_day')),\n",
    "                          yr_renovated=pl.col('yr_renovated').replace(0, None),\n",
    "                          )\n",
    "            .select(['id', 'price', 'bedrooms', 'bathrooms', 'sqft_living', 'sqft_lot', 'floors', \n",
    "                     'waterfront', 'view', 'condition', 'grade', 'sqft_above', 'sqft_basement', \n",
    "                     'yr_built', 'yr_renovated', 'zipcode', 'lat', 'long', 'sqft_living15', \n",
    "                     'sqft_lot15', 'date',  #'date_year', 'date_month', 'date_day', \n",
    "                     ])\n",
    "    )\n",
    "\n",
    "tweak_housing(raw)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Sklearn Pipelines\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# The difference between sklearn pipelines and transformers is \n",
    "# that a pipeline is a sequence of steps. A transformer transforms\n",
    "# the data, and a pipeline is a sequence of transformers.\n",
    "# A ColumnTransformer applies multiple transformers to different\n",
    "# columns of the input data.\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import FunctionTransformer\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "# use pandas output for sklearn\n",
    "from sklearn import set_config\n",
    "set_config(transform_output='polars')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(tweak_housing(raw).select(cs.numeric()).columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "numeric_features = ['bedrooms', 'bathrooms', 'sqft_living']\n",
    "std = StandardScaler()\n",
    "std.fit_transform(tweak_housing(raw).select(numeric_features))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "numeric_features = ['bedrooms', 'bathrooms', 'sqft_living']\n",
    "\n",
    "num_pipeline = Pipeline([\n",
    "     ('std', StandardScaler())])\n",
    "\n",
    "num_pipeline.fit_transform(\n",
    "    tweak_housing(raw)\n",
    "    .select(numeric_features)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# add another step\n",
    "numeric_features = ['bedrooms', 'bathrooms', 'sqft_living']\n",
    "\n",
    "num_pipeline = Pipeline([\n",
    "    ('imputer', SimpleImputer(strategy='median')),\n",
    "    ('std', StandardScaler())])\n",
    "\n",
    "num_pipeline.fit_transform(\n",
    "    tweak_housing(raw)\n",
    "    .select(numeric_features)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "cat_features = ['zipcode']\n",
    "\n",
    "ohe = OneHotEncoder(handle_unknown='ignore')\n",
    "#                    sparse_output=False)\n",
    "\n",
    "ohe.fit_transform(\n",
    "    tweak_housing(raw)\n",
    "    .select(cat_features)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "cat_features = ['zipcode']\n",
    "\n",
    "ohe = OneHotEncoder(handle_unknown='ignore',\n",
    "                    sparse_output=False)\n",
    "\n",
    "ohe.fit_transform(\n",
    "    tweak_housing(raw)\n",
    "    .select(cat_features)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "cat_features = ['zipcode']\n",
    "\n",
    "ohe = OneHotEncoder(handle_unknown='ignore',\n",
    "                    sparse_output=False, max_categories=10)\n",
    "\n",
    "ohe.fit_transform(\n",
    "    tweak_housing(raw)\n",
    "    .select(cat_features)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "cat_features = ['zipcode']\n",
    "\n",
    "cat_pipeline = Pipeline(steps=[\n",
    "    ('cat', OneHotEncoder(handle_unknown='ignore', sparse_output=False))])\n",
    "\n",
    "cat_pipeline.set_params(cat__max_categories=10)\n",
    "cat_pipeline.fit_transform(\n",
    "    tweak_housing(raw)\n",
    "    .select(cat_features)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transformer from a function\n",
    "tweak_transformer = FunctionTransformer(tweak_housing)\n",
    "\n",
    "tweak_transformer.fit_transform(raw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_features = ['zipcode']\n",
    "\n",
    "numeric_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='median')),\n",
    "    ('scaler', StandardScaler())])\n",
    "\n",
    "ct = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numeric_transformer, numeric_features),\n",
    "        ('cat', OneHotEncoder(handle_unknown='ignore',\n",
    "                              sparse_output=False), categorical_features)])\n",
    "\n",
    "ct.fit_transform(\n",
    "    tweak_housing(raw)\n",
    "    .select([*numeric_features, *cat_features])\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Custom transformer \n",
    "class ZipAvgPriceAdder(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self):\n",
    "        pass\n",
    "    def fit(self, X, y=None):\n",
    "        # assume X is a polars dataframe\n",
    "        self.zip_avg_price = (X\n",
    "                              .group_by('zipcode')\n",
    "                              .agg(zip_mean=pl.col('price').mean())\n",
    "        )\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X, y=None):\n",
    "        return X.join(self.zip_avg_price, on='zipcode')\n",
    "\n",
    "zip_adder = ZipAvgPriceAdder()\n",
    "zip_adder.fit_transform(raw.select(['zipcode', 'price']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# make the pipeline\n",
    "numeric_features = ['bedrooms', 'bathrooms', 'sqft_living', 'sqft_lot', 'floors', 'waterfront', 'view', \n",
    "                    'condition', 'grade', 'sqft_above', 'sqft_basement', 'yr_built', 'yr_renovated', \n",
    "                    'lat', 'long', 'sqft_living15', 'sqft_lot15', 'zip_mean']\n",
    "numeric_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='median')),\n",
    "    ('scaler', StandardScaler())])\n",
    "\n",
    "categorical_features = ['zipcode']\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numeric_transformer, numeric_features),\n",
    "        ('cat', OneHotEncoder(handle_unknown='ignore',\n",
    "                              sparse_output=False), categorical_features)])\n",
    "\n",
    "tweak_transformer = FunctionTransformer(tweak_housing)\n",
    "\n",
    "class ZipAvgPriceAdder(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self):\n",
    "        pass\n",
    "    def fit(self, X, y=None):\n",
    "        # assume X is a polars dataframe\n",
    "        self.zip_avg_price = (X\n",
    "                              .group_by('zipcode')\n",
    "                              .agg(zip_mean=pl.col('price').mean())\n",
    "        )\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X, y=None):\n",
    "        return X.join(self.zip_avg_price, on='zipcode')\n",
    "\n",
    "# Append classifier to preprocessing pipeline.\n",
    "# Now we have a full prediction pipeline.\n",
    "pipe = Pipeline(steps=[('tweak', tweak_transformer),\n",
    "                      ('zip_avg_price', ZipAvgPriceAdder()),\n",
    "                      ('preprocessor', preprocessor),\n",
    "                      ])\n",
    "\n",
    "X = raw #.drop('price')\n",
    "y = raw.select('price') # Note sklearn wants a Polars dataframe for y\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "pipe.fit_transform(raw, raw.select('price'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Note sklearn wants a Polars dataframe for y\n",
    "X = raw #.drop('price')\n",
    "y = raw.select('price') \n",
    "#y = raw['price']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "\n",
    "## Challenge\n",
    "\n",
    "Make a plot to explore the relationship between the number of bedrooms and the price of the house."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "# Model Creation\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Dummy Model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.dummy import DummyRegressor\n",
    "\n",
    "dummy = DummyRegressor(strategy='mean')\n",
    "y = raw.select('price')\n",
    "X_train, X_test, y_train, y_test = train_test_split(raw, y, test_size=0.2, random_state=42)\n",
    "dummy_pipe = Pipeline(steps=[('tweak', tweak_transformer),\n",
    "                      ('zip_avg_price', ZipAvgPriceAdder()),\n",
    "                      ('preprocessor', preprocessor),\n",
    "                      ('dummy', dummy),\n",
    "                      ])\n",
    "\n",
    "dummy_pipe.fit(X_train, y_train)\n",
    "dummy_pipe.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dummy_pipe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dummy_pipe.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Linear Regression\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "\n",
    "lr =  LinearRegression()\n",
    "y = raw.select('price')\n",
    "X_train, X_test, y_train, y_test = train_test_split(raw, y, test_size=0.2, random_state=42)\n",
    "lr_pipe = Pipeline(steps=[('tweak', tweak_transformer),\n",
    "                      ('zip_avg_price', ZipAvgPriceAdder()),\n",
    "                      ('preprocessor', preprocessor),\n",
    "                        ('lr', lr),\n",
    "                      ])\n",
    "\n",
    "lr_pipe.fit(X_train, y_train)\n",
    "lr_pipe.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_pipe.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Decision Trees\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeRegressor\n",
    "\n",
    "\n",
    "dt = DecisionTreeRegressor()\n",
    "y = raw.select('price')\n",
    "X_train, X_test, y_train, y_test = train_test_split(raw, y, test_size=0.2, random_state=42)\n",
    "dt_pipe = Pipeline(steps=[('tweak', tweak_transformer),\n",
    "                      ('zip_avg_price', ZipAvgPriceAdder()),\n",
    "                      ('preprocessor', preprocessor),\n",
    "                      ('dt', dt),\n",
    "                      ])\n",
    "\n",
    "dt_pipe.fit(X_train, y_train)\n",
    "dt_pipe.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt_pipe.set_params(dt__max_depth=1)\n",
    "dt_pipe.fit(X_train, y_train)\n",
    "dt_pipe.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt_pipe.set_params(dt__max_depth=9)\n",
    "dt_pipe.fit(X_train, y_train)\n",
    "dt_pipe.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## CatBoost\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from catboost import CatBoostRegressor\n",
    "\n",
    "\n",
    "cat = CatBoostRegressor()\n",
    "# has issues with Polars input going to use a pandas_transformer\n",
    "def to_pandas(df):\n",
    "    return df.to_pandas()\n",
    "pandas_transformer = FunctionTransformer(to_pandas)\n",
    "\n",
    "y = raw.select('price')\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(raw, y, test_size=0.2, random_state=42)\n",
    "cat_pipe = Pipeline(steps=[('tweak', tweak_transformer),\n",
    "                      ('zip_avg_price', ZipAvgPriceAdder()),\n",
    "                      ('preprocessor', preprocessor),\n",
    "                      ('to_pandas', pandas_transformer),\n",
    "                      ('cat', cat), \n",
    "                      ])\n",
    "\n",
    "cat_pipe.fit(X_train, y_train.to_numpy()[:,0])\n",
    "cat_pipe.score(X_test, y_test.to_numpy()[:,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Challenge\n",
    "\n",
    "Create a pipeline for a Random Forest model and train it on the data. (see `ensemble.RandomForestRegressor` in scikit-learn). What is the score?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "## Solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "# Evaluation\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## R2\n",
    "\n",
    "\n",
    "The Coefficient of Determination, R2, is a measure of how well the model fits the data. It is a value between 0 and 1. It tells us how much of the variance in the target variable is predictable from the features.\n",
    "\n",
    "A value of 0 means that the model explains none of the variability. A value of 1 means that the model explains all the variability.\n",
    "\n",
    "Note that it doesn't indicate whether a model is overfitting or underfitting the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "cat_pipe.score(X_test, y_test.to_numpy()[:,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Mean Squared/Absolute Error\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "mean_squared_error(y_test, cat_pipe.predict(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rmse\n",
    "mean_squared_error(y_test, cat_pipe.predict(X_test), squared=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# absolute error\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "mean_absolute_error(y_test, cat_pipe.predict(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compare to lr model\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "mean_absolute_error(y_test, lr_pipe.predict(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Residuals Plot\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make a residual plot\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "ax = plt.scatter(cat_pipe.predict(X_test), \n",
    "    y_test.to_series().to_numpy() - cat_pipe.predict(X_test), alpha=0.1)\n",
    "# make labels not be scientific notation\n",
    "plt.ticklabel_format(style='plain', axis='y')\n",
    "plt.ticklabel_format(style='plain', axis='x')\n",
    "plt.ylim(-500_000, 500_000)\n",
    "plt.xlabel('Predicted price')\n",
    "plt.ylabel('Residual')\n",
    "plt.title('Residual plot')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot with Polars\n",
    "(y_test\n",
    " .with_columns(predicted_price=cat_pipe.predict(X_test),\n",
    "   residual=y_test.to_series().to_numpy() - cat_pipe.predict(X_test))\n",
    " .plot.scatter('predicted_price', 'residual', alpha=0.1, yformatter='$%.0f',\n",
    "               xformatter='$%.0f')\n",
    " )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def residuals_plot(model, X_train, y_train, X_test, y_test):\n",
    "    return (y_test\n",
    "      .with_columns(prediction=model.predict(X_test),\n",
    "        residual=y_test.to_series().to_numpy() - model.predict(X_test),\n",
    "        type=pl.lit('test'))\n",
    "      .vstack(y_train\n",
    "        .with_columns(prediction=model.predict(X_train),\n",
    "          residual=y_train.to_series().to_numpy() - model.predict(X_train),\n",
    "          type=pl.lit('train'))\n",
    "              )\n",
    "      .reverse()\n",
    "      .plot.scatter('prediction', 'residual', alpha=0.1, yformatter='$%.0f',\n",
    "                    xformatter='$%.0f', by='type')\n",
    " )\n",
    "\n",
    "residuals_plot(cat_pipe, X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "residuals_plot(dt_pipe, X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Challenge\n",
    "\n",
    "What is the mean squared error of the Random Forest model? What is the R2 score? What do these values tell us about the model?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "## Solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Tuning\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Hyperparameters\n",
    "\n",
    "Hyperparameters are the levers we can pull to adjust the behavior of a model. They are set before the model is trained and remain constant during training."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Tuning Linear Regression\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_pipe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_pipe.named_steps['lr']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "help(lr_pipe.named_steps['lr'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Ridge\n",
    "Ridge?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rr =  Ridge()\n",
    "y = raw.select('price')\n",
    "X_train, X_test, y_train, y_test = train_test_split(raw, y, test_size=0.2, random_state=42)\n",
    "rr_pipe = Pipeline(steps=[('tweak', tweak_transformer),\n",
    "                      ('zip_avg_price', ZipAvgPriceAdder()),\n",
    "                      ('preprocessor', preprocessor),\n",
    "                        ('rr', rr),\n",
    "                      ])\n",
    "\n",
    "rr_pipe.fit(X_train, y_train)\n",
    "rr_pipe.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "lr_pipe.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import validation_curve\n",
    "\n",
    "param_range = [0, .01, .05, .1, .5, 1, 2]\n",
    "scores = []\n",
    "for val in param_range:\n",
    "    rr_pipe.set_params(rr__alpha=val)\n",
    "    rr_pipe.fit(X_train, y_train)\n",
    "    scores.append(rr_pipe.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Our be score is at 0 (which is normal Linear Regression)\n",
    "alpha = pl.DataFrame({'val': param_range,\n",
    "              'scores': scores})\n",
    "alpha.plot(x='val', y='scores')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Tuning Decision Trees\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dt_pipe.named_steps['dt']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "help(dt_pipe.named_steps['dt'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# plot a validation curve tracking mse as the max_depth of the decision tree increases\n",
    "from sklearn.model_selection import validation_curve\n",
    "\n",
    "param_range = range(1, 20)\n",
    "train_scores, test_scores = validation_curve(\n",
    "    dt_pipe, X_train, y_train, param_name=\"dt__max_depth\", param_range=param_range,\n",
    "    scoring=\"neg_mean_squared_error\", n_jobs=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make a validation curve from train_scores and test_scores\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "train_scores_mean = np.mean(train_scores, axis=1)\n",
    "train_scores_std = np.std(train_scores, axis=1)\n",
    "test_scores_mean = np.mean(test_scores, axis=1)\n",
    "test_scores_std = np.std(test_scores, axis=1)\n",
    "\n",
    "plt.title(\"Validation Curve with Decision Tree\")\n",
    "plt.xlabel(\"max_depth\")\n",
    "plt.ylabel(\"Score\")\n",
    "#plt.ylim(-1, 0)\n",
    "lw = 2\n",
    "plt.plot(param_range, train_scores_mean, label=\"Training score\",\n",
    "             color=\"darkorange\", lw=lw)\n",
    "plt.fill_between(param_range, train_scores_mean - train_scores_std,\n",
    "                 train_scores_mean + train_scores_std, alpha=0.2,\n",
    "                 color=\"darkorange\", lw=lw)\n",
    "plt.plot(param_range, test_scores_mean, label=\"Cross-validation score\",\n",
    "                color=\"navy\", lw=lw)\n",
    "\n",
    "plt.fill_between(param_range, test_scores_mean - test_scores_std,   \n",
    "                    test_scores_mean + test_scores_std, alpha=0.2,\n",
    "                    color=\"navy\", lw=lw)\n",
    "plt.legend(loc=\"best\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train dt_pipe with max_depth=8\n",
    "dt8_pipe = Pipeline(steps=[('tweak', tweak_transformer),\n",
    "                        ('zip_avg_price', ZipAvgPriceAdder()),\n",
    "                        ('to_pandas', pandas_transformer),\n",
    "                        ('preprocessor', preprocessor),\n",
    "                        ('dt', DecisionTreeRegressor(max_depth=8)),\n",
    "                        ])\n",
    "\n",
    "dt8_pipe.fit(X_train, y_train)\n",
    "dt8_pipe.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "mean_squared_error(y_test, dt8_pipe.predict(X_test), squared=False) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt_pipe.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_squared_error(y_test, dt_pipe.predict(X_test), squared=False) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Tuning CatBoost\n",
    "\n",
    "* Boosting - `iterations` (`num_trees`, `n_estimators`), `learning_rate` (`eta`), `early_stopping_rounds`\n",
    "\n",
    "* Tree based - `depth` (`max_depth`), `grow_policy`, `min_child_samples` (`min_data_in_leaf`), `max_leaves` (`num_leaves`)\n",
    "\n",
    "* Sampling - `subsample`, `sampling_frequency`, `rsm` (`colsample_bylevel`), `random_strength`, `bagging_temperature`\n",
    "\n",
    "* Regularization - `l2_leaf_reg` (`reg_lambda`), `model_shrink_rate`\n",
    "\n",
    "* Constraints - `monotone_constraints`, `feature_weights`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "catboost.CatBoostRegressor?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cr2 = catboost.CatBoostRegressor(iterations=3000, learning_rate=0.1,\n",
    "                                 early_stopping_rounds=10)\n",
    "X_train, X_test, y_train, y_test = train_test_split(raw.drop('price'), y, \n",
    "                                                    test_size=0.2, random_state=42)\n",
    "\n",
    "cr2.fit(X_train.to_pandas(), y_train.to_numpy(), cat_features=['zipcode'], verbose=100,\n",
    "        early_stopping_rounds=10, eval_set=(X_test.to_pandas(), y_test.to_numpy()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# plot a validation curve tracking mse as the max_depth of the decision tree increases\n",
    "from sklearn.model_selection import validation_curve\n",
    "\n",
    "param_range = range(1, 10)\n",
    "train_scores, test_scores = validation_curve(\n",
    "    cr2, X_train.to_pandas(), y_train.to_numpy(), param_name=\"max_depth\", \n",
    "    param_range=param_range,\n",
    "    scoring=\"neg_mean_squared_error\", n_jobs=1,\n",
    "    fit_params=dict(early_stopping_rounds=10, \n",
    "                    eval_set=(X_test.to_pandas(), y_test.to_numpy())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make a validation curve from train_scores and test_scores\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "train_scores_mean = np.mean(train_scores, axis=1)\n",
    "train_scores_std = np.std(train_scores, axis=1)\n",
    "test_scores_mean = np.mean(test_scores, axis=1)\n",
    "test_scores_std = np.std(test_scores, axis=1)\n",
    "\n",
    "plt.title(\"Validation Curve with CatBoost\")\n",
    "plt.xlabel(\"max_depth\")\n",
    "plt.ylabel(\"Score\")\n",
    "#plt.ylim(-1, 0)\n",
    "lw = 2\n",
    "plt.plot(param_range, train_scores_mean, label=\"Training score\",\n",
    "             color=\"darkorange\", lw=lw)\n",
    "plt.fill_between(param_range, train_scores_mean - train_scores_std,\n",
    "                 train_scores_mean + train_scores_std, alpha=0.2,\n",
    "                 color=\"darkorange\", lw=lw)\n",
    "plt.plot(param_range, test_scores_mean, label=\"Cross-validation score\",\n",
    "                color=\"navy\", lw=lw)\n",
    "\n",
    "plt.fill_between(param_range, test_scores_mean - test_scores_std,   \n",
    "                    test_scores_mean + test_scores_std, alpha=0.2,\n",
    "                    color=\"navy\", lw=lw)\n",
    "plt.legend(loc=\"best\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set max_depth to 4\n",
    "cr2_4 = catboost.CatBoostRegressor(iterations=3000, learning_rate=0.1,\n",
    "                                max_depth=4)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(raw.drop('price'), y, \n",
    "                                                    test_size=0.2, random_state=42)\n",
    "\n",
    "cr2_4.fit(X_train.to_pandas(), y_train.to_numpy(), cat_features=['zipcode'], verbose=100,\n",
    "        early_stopping_rounds=10, eval_set=(X_test.to_pandas(), y_test.to_numpy()))\n",
    "cr2_4.score(X_test.to_pandas(), y_test.to_numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Grid Search\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeRegressor\n",
    "\n",
    "\n",
    "dt = DecisionTreeRegressor()\n",
    "y = raw.select('price')\n",
    "X_train, X_test, y_train, y_test = train_test_split(raw, y, test_size=0.2, random_state=42)\n",
    "dt_pipe = Pipeline(steps=[('tweak', tweak_transformer),\n",
    "                      ('zip_avg_price', ZipAvgPriceAdder()),\n",
    "                      ('preprocessor', preprocessor),\n",
    "                      ('dt', dt),\n",
    "                      ])\n",
    "\n",
    "dt_pipe.fit(X_train, y_train)\n",
    "dt_pipe.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dt_pipe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# use grid search on decision tree\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "param_grid = {\n",
    "    'dt__max_depth': [3, 6, 9],\n",
    "    'dt__min_samples_split': [10, 20, 100],\n",
    "    'dt__min_samples_leaf': [10, 20, 100],\n",
    "}\n",
    "\n",
    "grid_search = GridSearchCV(dt_pipe, param_grid, cv=5)#, scoring='neg_mean_squared_error')\n",
    "grid_search.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_search.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# make a tree from the params\n",
    "dt = DecisionTreeRegressor()#max_depth=9, min_samples_leaf=20, min_samples_split=10)\n",
    "dt_pipe = Pipeline(steps=[('tweak', tweak_transformer),\n",
    "                      ('zip_avg_price', ZipAvgPriceAdder()),\n",
    "                      ('to_pandas', pandas_transformer),\n",
    "                      ('preprocessor', preprocessor),\n",
    "                        ('dt', dt),\n",
    "                      ])\n",
    "dt_pipe.set_params(**grid_search.best_params_)\n",
    "dt_pipe.fit(X_train, y_train)\n",
    "dt_pipe.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# compare to default\n",
    "dt = DecisionTreeRegressor(random_state=42)\n",
    "dt_pipe = Pipeline(steps=[('tweak', tweak_transformer),\n",
    "                      ('zip_avg_price', ZipAvgPriceAdder()),\n",
    "                      ('to_pandas', pandas_transformer),\n",
    "                      ('preprocessor', preprocessor),\n",
    "                        ('dt', dt),\n",
    "                      ])\n",
    "\n",
    "dt_pipe.fit(X_train, y_train)\n",
    "dt_pipe.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Challenge\n",
    "\n",
    "Do a grid search to find the best depth for the random forest model. What is the best depth? What is the score of the model with the best depth?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Deployment\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## End to end notebook\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import polars as pl\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import FunctionTransformer\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "# use pandas output for sklearn\n",
    "from sklearn import set_config\n",
    "set_config(transform_output='polars')\n",
    "\n",
    "def tweak_housing(df):\n",
    "    return (df\n",
    "            .with_columns(zipcode=pl.col('zipcode').cast(pl.String).cast(pl.Categorical),\n",
    "                          date=pl.date(pl.col('date_year'), pl.col('date_month'), pl.col('date_day')),\n",
    "                          yr_renovated=pl.col('yr_renovated').replace(0, None),\n",
    "                          )\n",
    "            .select(['id', 'price', 'bedrooms', 'bathrooms', 'sqft_living', 'sqft_lot', 'floors', \n",
    "                     'waterfront', 'view', 'condition', 'grade', 'sqft_above', 'sqft_basement', \n",
    "                     'yr_built', 'yr_renovated', 'zipcode', 'lat', 'long', 'sqft_living15', \n",
    "                     'sqft_lot15', 'date',  #'date_year', 'date_month', 'date_day', \n",
    "                     ])\n",
    "    )\n",
    "\n",
    "# make the pipeline\n",
    "numeric_features = ['bedrooms', 'bathrooms', 'sqft_living', 'sqft_lot', 'floors', 'waterfront', 'view', \n",
    "                    'condition', 'grade', 'sqft_above', 'sqft_basement', 'yr_built', 'yr_renovated', \n",
    "                    'lat', 'long', 'sqft_living15', 'sqft_lot15', 'zip_mean']\n",
    "numeric_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='median')),\n",
    "    ('scaler', StandardScaler())])\n",
    "\n",
    "categorical_features = ['zipcode']\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numeric_transformer, numeric_features),\n",
    "        ('cat', OneHotEncoder(handle_unknown='ignore',\n",
    "                              sparse_output=False), categorical_features)])\n",
    "\n",
    "def to_pandas(df):\n",
    "    return df.to_pandas()\n",
    "pandas_transformer = FunctionTransformer(to_pandas)\n",
    "\n",
    "tweak_transformer = FunctionTransformer(tweak_housing)\n",
    "\n",
    "class ZipAvgPriceAdder(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self):\n",
    "        pass\n",
    "    def fit(self, X, y=None):\n",
    "        # assume X is a polars dataframe\n",
    "        self.zip_avg_price = (X\n",
    "                              .group_by('zipcode')\n",
    "                              .agg(zip_mean=pl.col('price').mean())\n",
    "        )\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X, y=None):\n",
    "        with pl.StringCache():\n",
    "            return X.join(self.zip_avg_price, on='zipcode')\n",
    "\n",
    "\n",
    "# King County House Sales dataset from OpenML (includes Seattle)\n",
    "# this is an ARFF file, which is a text file with a specific format\n",
    "url = 'https://www.openml.org/data/download/22044765/dataset'\n",
    "cols = ['id', 'price', 'bedrooms', 'bathrooms', 'sqft_living', 'sqft_lot', 'floors', 'waterfront', 'view', \n",
    "        'condition', 'grade', 'sqft_above', 'sqft_basement', 'yr_built', 'yr_renovated',\n",
    "        'zipcode', 'lat', 'long', 'sqft_living15', 'sqft_lot15', 'date_year', 'date_month', 'date_day']\n",
    "\n",
    "raw = pl.read_csv(url, new_columns=cols, skip_rows=31, has_header=False)\n",
    "\n",
    "lr =  LinearRegression()\n",
    "y = raw.select('price')\n",
    "X_train, X_test, y_train, y_test = train_test_split(raw, y, test_size=0.2, random_state=42)\n",
    "lr_pipe = Pipeline(steps=[('tweak', tweak_transformer),\n",
    "                      ('zip_avg_price', ZipAvgPriceAdder()),\n",
    "                      ('preprocessor', preprocessor),\n",
    "                      ('lr', lr),\n",
    "                      ])\n",
    "\n",
    "lr_pipe.fit(X_train, y_train)\n",
    "lr_pipe.score(X_test, y_test)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using MLFlow\n",
    "\n",
    "Going to show how to persist and load a model, but can also:\n",
    "\n",
    "- Start a endpoint to serve predictions\n",
    "- Build a Docker image\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mlflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlflow.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_info = mlflow.sklearn.log_model(lr_pipe, artifact_path='lr_pipe')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_info.artifact_path    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_info.run_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = mlflow.pyfunc.load_model(f'mlruns/0/{model_info.run_id}/artifacts/lr_pipe')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Challenge\n",
    "\n",
    "Reformat your notebook so that you can load the data and create an optimized random forest model in a single cell. Then, use MLFlow to log the model and its parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Solution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
